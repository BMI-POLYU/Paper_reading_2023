# Paper Reading 2023

| Date | Presenter | Title | Keywords | Others Resources |
| -- | -- | -- | -- | -- |
| 1/4  | Yang Qu | [Embodied Intelligence via Learning and Evolution (Nature Communications)](https://www.nature.com/articles/s41467-021-25874-z) | | |
| 1/4  | Song Zeyang | [A convolutional neural-network framework for modelling auditory sensory cells and synapses (Nature Communications Biology)](https://www.nature.com/articles/s42003-021-02341-5) | | |
| 1/11 | Chen Xinyi | [Exploring the Brain-like Properties of Deep Neural Networks A Neural Encoding Perspective](https://link.springer.com/content/pdf/10.1007/s11633-022-1348-x.pdf?pdf=button%20sticky) | | |
| 1/11 | Ma Chenxiang | [A Computational Model for Storing Memories in the Synaptic Structures of the Brain](https://www.biorxiv.org/content/10.1101/2022.10.21.513291v1) | | |
| 1/18 | Yang Qu | [Network Binarization via Contrastive Learning](https://arxiv.org/pdf/2207.02970.pdf) | | |
| 1/18 | Song Zeyang| [Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs](https://cbmm.mit.edu/sites/default/files/publications/2019-10-28%20NeurIPS-camera_ready.pdf) | | |
| 1/25 | Chen Xinyi | [Understanding the role of individual units in a deep neural network.](https://www.pnas.org/doi/full/10.1073/pnas.1907375117) | | |
| 1/25 | Ma Chenxiang | [SimAM: A Simple, Parameter-Free Attention Module for Convolutional Neural Networks (ICML-21)](https://ruyuanzhang.github.io/files/2107_ICML.pdf) | | |
| 2/1  | Yang Qu | [RecDis-SNN: Rectifying Membrane Potential Distribution for Directly Training Spiking Neural Networks (CVPR 22)](http://openaccess.thecvf.com//content/CVPR2022/html/Guo_RecDis-SNN_Rectifying_Membrane_Potential_Distribution_for_Directly_Training_Spiking_Neural_CVPR_2022_paper.html) | | |
| 2/1 | Song Zeyang | [DDDM: A Brain-Inspired Framework for Robust Classification (IJCAI-22)](https://www.ijcai.org/proceedings/2022/0397.pdf) | | |

# Presentation Slides 
[Google Drive](https://drive.google.com/drive/folders/1LesEh5-bRQO0hIiFL4h5mPsh9ewuJ9go?usp=share_link) 

# Continue Updating
- Backpropagation through the Void: Optimizing control variates for black-box gradient estimation
- Convolutional Neural Networks as a Model of the Visual System: Past, Present, and Future
- Replay in Deep Learning: Current Approaches and Missing Biological Elements 
- Perception in real-time: predicting the present, reconstructing the past
- Evolutionary training and abstraction yields algorithmic generalization of neural computers
- Compartmentalized dendritic plasticity during associative learning (Science)
- Current State and Future Directions for Learning in Biological Recurrent Neural Networks: A Perspective Piece
- Hypothesis-driven Online Video Stream Learning with Augmented Memory（https://arxiv.org/abs/2104.02206）
- GAN Memory with No Forgetting (NIPS 2020)](https://papers.nips.cc/paper/2020/file/bf201d5407a6509fa536afc4b380577e-Paper.pdf)
- Transfer without Forgetting https://arxiv.org/pdf/2206.00388.pdf
- Towards mental time travel: a hierarchical memory for reinforcement learning agents
- Memory-inspired spiking hyperdimensional network for robust online learning
- Dendritic predictive coding: A theory of cortical computation with spiking neurons https://arxiv.org/pdf/2205.05303.pdf
- Beyond accuracy: generalization properties of bio-plausible temporal credit assignment rules https://arxiv.org/pdf/2206.00823.pdf
- Biologically-plausible backpropagation through arbitrary timespans via local neuromodulators https://arxiv.org/pdf/2206.01338.pdf
- Neuromorphic computing chip with spatiotemporal elasticity for multi-intelligent-tasking robots
- Spike Calibration: Fast and Accurate Conversion of Spiking Neural Network for Object Detection and Segmentation
- Learning in deep neural networks and brains with similarity-weighted interleaved learning (PNAS)
- Gradient-based Neuromorphic Learning on Dynamical RRAM Arrays (https://arxiv.org/pdf/2206.12992.pdf)
- Modeling Associative Plasticity between Synapses to Enhance Learning of Spiking Neural Networks https://arxiv.org/pdf/2207.11670.pdf
- Single-phase deep learning in cortico-cortical networks (https://arxiv.org/pdf/2206.11769.pdf)
- Online Normalization for Training Neural Networks (https://papers.nips.cc/paper/2019/hash/cb3ce9b06932da6faaa7fc70d5b5d2f4-Abstract.html)
- Neuro-symbolic computing with spiking neural networks (https://arxiv.org/pdf/2208.02576.pdf)
- Cell-type-specific integration of feedforward and feedback synaptic inputs in the posterior parietal cortex (NEURON)
- Optimizing Recurrent Spiking Neural Networks with Small Time Constants for Temporal Tasks
- Multimodal Speech Enhancement Using Burst Propagation
- Benchmarking Neuromorphic Computing for Inference (https://www.researchgate.net/profile/Simon-Narduzzi/publication/362412429_Benchmarking_Neuromorphic_Computing_for_Inference/links/630735aa61e4553b95389cf0/Benchmarking-Neuromorphic-Computing-for-Inference.pdf)
- Cognitive Neuroscience of Time: Nows, Timelines, and Chronologies
- Interactive continual learning for robots: a neuromorphic approach http://sandamirskaya.eu/resources/Interactive_Continual_Learning_for_Robots__Neuromorphic_Approach__ICONS_.pdf
- The neural coding framework for learning generative models
- Continual Learning of Recurrent Neural Networks by Locally Aligning Distributed Representations
- The cortical column: a structure without a function
- Learning on Arbitrary Graph Topologies via Predictive Coding https://arxiv.org/pdf/2201.13180.pdf
- Online Training Through Time for Spiking Neural Networks https://arxiv.org/pdf/2210.04195.pdf
- STSC-SNN: Spatio-Temporal Synaptic Connection with Temporal Convolution and Attention for Spiking Neural Networks https://arxiv.org/pdf/2210.05241.pdf
- Denoised Internal Models: A Brain-inspired Autoencoder Against Adversarial Attacks
- Towards a New Paradigm for Brain-inspired Computer Vision
- Towards Accurate, Energy-Efficient, & Low-Latency Spiking LSTMs
- An Analytical Estimation of Spiking Neural Networks Energy Efficiency
- Sparse bursts optimize information transmission in a multiplexed neural code (PNAS)
- Current State and Future Directions for Learning in Biological Recurrent Neural Networks: A Perspective Piece
- [Spike Transformer: Monocular Depth Estimation for Spiking Camera (ECCV 22)](http://www.ecva.net/papers/eccv_2022/papers_ECCV/html/3125_ECCV_2022_paper.php)
- [Towards Ultra Low Latency Spiking Neural Networks for Vision and Sequential Tasks Using Temporal Pruning (ECCV 22)](http://www.ecva.net/papers/eccv_2022/papers_ECCV/html/6421_ECCV_2022_paper.php)
- [Real Spike: Learning Real-Valued Spikes for Spiking Neural Networks (ECCV 22)](http://www.ecva.net/papers/eccv_2022/papers_ECCV/html/6623_ECCV_2022_paper.php)
- Recent Advances at the Interface of Neuroscience and Artificial Neural Networks
- Neuromorphic Data Augmentation for Training Spiking Neural Networks (ECCV 22)
- Event-Based Video Reconstruction Via Potential-Assisted Spiking Neural Network (CVPR 22)
- Spikeformer: A Novel Architecture for Training High-Performance Low-Latency Spiking Neural Network [https://arxiv.org/pdf/2211.10686.pdf]
- Liquid Time-constant Networks https://arxiv.org/pdf/2006.04439.pdf
- Beyond spiking networks: the computational advantages of dendritic amplification and input segregation
- Time-encoded multiplication-free spiking neural networks: application to data classification tasks https://link.springer.com/content/pdf/10.1007/s00521-022-07910-1.pdf?pdf=button
- Insect-Inspired Spiking Neural Controllers for Adaptive Behaviors in Bio-Robots https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9955469&tag=1
- A data-based large-scale model for primary visual cortex enables brain-like robust and versatile visual processing [https://www.science.org/doi/10.1126/sciadv.abq7592]
- Sleep-like unsupervised replay reduces catastrophic forgetting in artificial neural networks [https://www.nature.com/articles/s41467-022-34938-7]
- SYNAPTIC DYNAMICS REALIZE FIRST-ORDER ADAPTIVE LEARNING AND WEIGHT SYMMETRY [https://arxiv.org/pdf/2212.09440.pdf]
- SNN: Time step reduction of spiking surrogate gradients for training energy efficient single-step spiking neural networks [https://www.sciencedirect.com/science/article/pii/S0893608022005007]
- Exact Error Backpropagation Through Spikes for Precise Training of Spiking Neural Networks [https://arxiv.org/pdf/2212.09500.pdf]
- HOYER REGULARIZER IS ALL YOU NEED FOR ULTRA LOW-LATENCY SPIKING NEURAL NETWORKS [https://arxiv.org/pdf/2212.10170.pdf]
- Learning efficient backprojections across cortical hierarchies in real time [https://arxiv.org/pdf/2212.10249.pdf]
- Synaptic basis of a sub-second representation of time in a neural circuit model [https://www.nature.com/articles/s41467-022-35395-y]
- AN EXACT MAPPING FROM RELU NETWORKS TO SPIKING NEURAL NETWORKS [https://arxiv.org/pdf/2212.12522.pdf]
