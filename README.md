# Paper Reading 2022

| Date | Presenter | Title | Keywords | Others Resources |
| -- | -- | -- | -- | -- |
| 4/6 | Yang Qu | [Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks (ICLR 2022)](https://openreview.net/forum?id=7B3IJMM1k_M)| Spiking Neural Networks, ANN-SNN Conversion, Ultra-low Latency, Quantization Clip-floor-shift Activation|[code](https://github.com/putshua/SNN_conversion_QCFS)|
| 4/6 | Yang Qu | [Optimized Potential Initialization for Low-latency Spiking Neural Networks (AAAI 2022)](https://www.aaai.org/AAAI22Papers/AAAI-3681.BuT.pdf)| Spiking Neural Networks, ANN-SNN Conversion, Potential Initialization, Integrate-and-fire Neuron | N/A |
| 4/6 | Yang Qu | [Optimal Conversion of Conventional Artificial Neural Networks to Spiking Neural Networks (ICLR 2021)](https://openreview.net/pdf?id=FZ1oTwcXchK)| Spiking Neural Networks, ANN-SNN Conversion, weight balance, second-order approximation | [code](https://github.com/Jackn0/snn_optimal_conversion_pipeline) |
| 4/13 | Yang Qu | [A Free Lunch From ANN: Towards Efficient, Accurate Spiking Neural Networks Calibration (ICML 2021)](http://proceedings.mlr.press/v139/li21d.html)| Spiking Neural Network (SNN), ANN-to-SNN conversion, Layer-wise Calibration | [code](https://github.com/yhhhli/SNN_Calibration) |
| 4/13 | Chen Xinyi | [Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks (IJCAI 2021)](https://www.ijcai.org/proceedings/2021/321)| Spiking Neural Networks, ANN-SNN Conversion, Rate Norm Layer, Inference Delay | [code](https://github.com/DingJianhao/OptSNNConvertion-RNL-RIL) |
| 4/13 | Song Zeyang| [Dynamic Neural Networks: A Survey ](https://arxiv.org/pdf/2102.04906.pdf)| Spiking Neural Network (SNN), Dynamic Neural Network, Network architecture | N/A |
| 4/20 | Yang Qu | [Temporal Efficient Training of Spiking Neural Network Via Gradient Re-weighting (ICLR 2022)](https://openreview.net/forum?id=_XNtisL32jv)|Spiking Neural Networks (SNNs), Direct Training, Surrogate Gradient, Generalizability |[code](https://github.com/Gus-Lab/temporal_efficient_training)|
| 4/20 | Chen Xinyi | [Going Deeper With Directly-Trained Larger Spiking Neural Networks (AAAI 2021)](https://ojs.aaai.org/index.php/AAAI/article/view/17320)|Spiking Neural Networks, Directly training of deep SNN, STBP-tdBN, Batch normalization |[others](https://arxiv.org/abs/2112.08954) |
| 4/20 | Song Zeyang | [Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/abs/1901.02860)|Transformer, Memory, Sequential processing|[code](https://github.com/kimiyoung/transformer-xl)|
| 4/20 | Song Zeyang | [Compressive Transformers for Long-Range Sequence Modelling](https://openreview.net/forum?id=SylKikSYDH)|Transformer, Memory, Sequential processing|[code](https://github.com/lucidrains/compressive-transformer-pytorch)|
| 4/27 | Yang Qu | [Temporal-Coded Deep Spiking Neural Network with Easy Training and Robust Performance (AAAI 2021)](https://ojs.aaai.org/index.php/AAAI/article/view/17329)|Spiking Neural Networks (SNNs), Direct Training, Bio-inspired Learning, Temporal-coding |[code](https://github.com/zbs881314/Temporal-Coded-Deep-SNN) |
| 4/27 | Chen Xinyi | [Backpropagated Neighborhood Aggregation for Accurate Training of Spiking Neural Networks (ICML 2021)](http://proceedings.mlr.press/v139/yang21n.html)|Spiking Neural Networks, Neighborhood aggregation, Directly training, Distance function|N/A |
| 4/27 | Song Zeyang | [Advancing Residual Learning towards Powerful Deep Spiking Neural Networks](https://arxiv.org/abs/2112.08954)|Deep SNN, residual |N/A |
| 5/4 | Yang Qu | [Training Feedback Spiking Neural Networks by Implicit Differentiation on the Equilibrium State (NEURIPS21)](https://arxiv.org/abs/2109.14247)|Spiking Neural Networks (SNNs), Direct Training, Implicit differentiation, Equilibrium of Neural Networks|[code](https://github.com/pkuxmq/IDE-FSNN) |
| 5/4 | Chen Xinyi | [Deep Residual Learning in Spiking Neural Networks (NIPS 2021)](https://papers.nips.cc/paper/2021/hash/afe434653a898da20044041262b3ac74-Abstract.html)|Spiking Neural Networks, Spike element-wise ResNet, Residual learning, Directly training|N/A |
| 5/4 | Song Zeyang | [Sparse Spiking Gradient Descent (NIPS 2021)](https://papers.nips.cc/paper/2021/hash/61f2585b0ebcf1f532c4d1ec9a7d51aa-Abstract.html)|Spiking Neural Network (SNN), Backpropagation, Sparse network|[code](https://github.com/npvoid/SparseSpikingBackprop)|
| 5/18 | Yang Qu | [Differentiable Spike: Rethinking Gradient-Descent for Training Spiking Neural Networks (NIPS 2021)](https://proceedings.neurips.cc/paper/2021/file/c4ca4238a0b923820dcc509a6f75849b-Paper.pdf)|Spiking Neural Networks (SNNs), Direct Training, Surrogate Gradient| N/A |
| 5/18 | Chen Xinyi | [Deep Spiking Neural Network with Neural Oscillation and Spike-Phase Information (AAAI 2021)](https://ojs.aaai.org/index.php/AAAI/article/view/16870)|Spiking Neural Networks, Resonate Spiking Neuron (RSN), Spike-Level-Dependent Back-Propagation (SLDBP), Oscillation Postsynaptic Potential |N/A |
| 5/18 | Song Zeyang | [Temporal-Wise Attention Spiking Neural Networks for Event Streams Classification (ICCV 2021)](https://openaccess.thecvf.com/content/ICCV2021/html/Yao_Temporal-Wise_Attention_Spiking_Neural_Networks_for_Event_Streams_Classification_ICCV_2021_paper.html)|Spiking Neural Network (SNN), temporal attention, event stream |N/A |
| 5/25 | Yang Qu | [A Differentiable Point Process with Its Application to Spiking Neural Networks (ICML 2021)](http://proceedings.mlr.press/v139/kajino21a.html)|Spiking Neural Networks (SNNs), Temporal Point Process, Gradient estimator, Probabilistic model, conditional intensity function|[code](https://github.com/ibm-research-tokyo/diffsnn)|
| 5/25 | Chen Xinyi | [Pruning of Deep Spiking Neural Networks Through Gradient Rewiring (IJCAI 2021)](https://www.ijcai.org/proceedings/2021/236)| Spiking Neural Networks, Pruning approach, Gradient rewiring|[code](https://github.com/Yanqi-Chen/Gradient-Rewiring)|
| 5/25 | Song Zeyang | [SpikeConverter: An Efficient Conversion Framework Zipping the Gap between Artificial Neural Networks and Spiking Neural Networks (AAAI 2022](https://www.aaai.org/AAAI22Papers/AAAI-364.LiuF.pdf)|Conversion|N/A |
| 6/1 | Yang Qu | [Learning to Time-Decode in Spiking Neural Networks Through The Information Bottleneck (NIPS 2021)](https://arxiv.org/pdf/2106.01177.pdf)|Spiking Neural Networks (SNNs), Hybrid SNN-ANN architectures, Information Bottleneck| N/A |
| 6/1 | Chen Xinyi | [Spiking Neural Networks with Improved Inherent Recurrence Dynamics for Sequential Learning (AAAI 2022)](https://www.aaai.org/AAAI22Papers/AAAI-8838.PonghiranW.pdf)|Spiking Neural Networks, Sequential task, Inherence recurrence, Multi-bit value output, Energy consumption| N/A |
| 6/1 | Song Zeyang |[MAP-SNN: Mapping Spike Activities with Multiplicity, Adaptability, and Plasticity into Bio-Plausible Spiking Neural Networks](https://arxiv.org/pdf/2204.09893.pdf)|Spiking Neural Network (SNN) |N/A |
| 6/8 | Yang Qu | [On-chip training spiking neural networks using approximated backpropagation with analog synaptic devices (Frontier in Neuroscience)](https://www.frontiersin.org/articles/10.3389/fnins.2020.00423/full)|neuromorphic, spiking neural networks, deep neural networks, on-chip training, supervised learning, hardware-based neural networks, synaptic devices|N/A |
| 6/8 | Chen Xinyi |[Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation (CVPR22)](https://arxiv.org/pdf/2205.00459.pdf)|Spiking Neural Networks, Differentiation on Spike Representation, Sub-differentiable mapping, Mapping error|[code](https://github.com/qymeng94/DSR)|
| 6/8 | Song Zeyang |[Efficient and Accurate Conversion of Spiking Neural Network with Burst Spikes (IJCAI22)](https://arxiv.org/abs/2204.13271)|Spiking Neural Network(SNN), ANN-SNN Conversion|[code](https://github.com/Brain-Inspired-Cognitive-Engine/Conversion_Burst) |
| 6/15 | Yang Qu | [Accelerating Spatiotemporal Supervised Training of Large-Scale Spiking Neural Networks on GPU (DATE22)](https://dl.acm.org/doi/abs/10.5555/3539845.3540007) |Neuromorphic Computing, Spiking Neural Network, GPU Optimization, Training Acceleration |[code](https://github.com/liangling76/snn_gpu_training_bptt) |
| 6/15 | Chen Xinyi | [Accelerating spiking neural network training](https://arxiv.org/pdf/2205.15286.pdf) |Spiking Neural Networks, Speedup training, Parallelisable computation, FastSNN |N/A |
| 6/15 | Song Zeyang | [Research and implementation of GPU-based parallelization of spiking neural network](https://ieeexplore.ieee.org/abstract/document/9777367) |Spiking Neural Network(SNN), GPU parallel acceleration |N/A |
| 6/22 | Yang Qu | [EXODUS: Stable and Efficient Training of Spiking Neural Networks](https://arxiv.org/pdf/2205.10242.pdf) |Neuromorphic Computing, Spiking Neural Network (SNN), Direct Training, Surrogate Gradient| [code](https://github.com/synsense/sinabs-exodus) |
| 6/22 | Song Zeyang | [A Hybrid Spiking Neurons Embedded LSTM Network for Multivariate Time Series Learning under Concept-drift Environment (IEEE TKDE) ](https://ieeexplore.ieee.org/abstract/document/9783029/authors#authors) |Spiking Neural Network(SNN), LSTM, long-term memory|[code](https://github.com/Brain-Inspired-Cognitive-Engine/Conversion_Burst) |
| 6/29 | Yang Qu | [Rethinking Pretraining as a Bridge from ANNs to SNNs](https://arxiv.org/abs/2203.01158#:~:text=Spiking%20neural%20networks%20(SNNs)%20are,and%20low%20power%20consumption%20properties.) |Spiking Neural Network (SNN), Transfer learning, Hybrid Training | N/A |
| 6/29 | Chen Xinyi | [DPSNN: A Differentially Private Spiking Neural Network](https://arxiv.org/pdf/2205.12718.pdf) |Spiking Neural Networks, Differential privacy, clipping gradient, privacy attacks |N/A |
| 6/29 | Chen Xinyi | [EventMix: An Efficient Augmentation Strategy for Event-Based Data](https://arxiv.org/pdf/2205.12054.pdf) |Spiking Neural Networks, Event stream datasets, Data augmentation, EventMix | N/A |
| 6/29 | Song Zeyang | [Memory-enriched Computation and Learning in Spiking Neural Network Through Hebbian Plasticity](https://arxiv.org/pdf/2205.11276.pdf) |Spiking Neural Network(SNN), Memory, Hegbian learning |[code](https://github.com/IGITUGraz/MemoryDependentComputation) |
| 7/6 | Yang Qu | [Neurons learn by predicting future activity (Nature Machine Intelligence)](https://www.nature.com/articles/s42256-021-00430-y) |Spiking Neural Network (SNN), Predictive learning, neuroscience |[code](https://github.com/ykubo82/bioCHL)|
| 7/20 | Chen Xinyi | [Biological underpinnings for lifelong learning machines (Nature Machine Intelligence)](https://www.nature.com/articles/s42256-022-00452-0) |Life long learning, Biological mechanism, Artificial intelligence | N/A |
| 7/27 | Song Zeyang | [Optimizing agent behavior over long time scales by transporting value (Nature Communication)](https://www.nature.com/articles/s41467-019-13073-w) |Spiking Neural Network(SNN), Long term memory, Reinforcement Learning|[code](https://github.com/deepmind/tvt)|
| 8/10  | Yang Qu | [Neural heterogeneity promotes robust learning (Nature Communication)](https://www.nature.com/articles/s41467-021-26022-3) |Spiking Neural Network (SNN), Neural heterogeneity, robust learning |[code](https://github.com/npvoid/neural_heterogeneity)|
| 8/10 | Chen Xinyi | [Synaptic metaplasticity in binarized neural networks. (Nature Communication)](https://www.nature.com/articles/s41467-021-22768-y) |Synaptic metaplasticity, binarized neural network, catastrophic forgetting, continual learning|[code](https://github.com/LaborieuxAxel/SynapticMetaplasticityBNN)|
| 8/17 | Song Zeyang | [A framework for the general design and computation of hybrid neural networks(Nature Communication)](https://www.nature.com/articles/s41467-022-30964-7.pdf) |Spiking neural network, hybrid neural network|[code](https://github.com/IbrahimYang/Hybrid-neural-networks) |
| 8/24 | Yang Qu | [Bioinspired multisensory neural network with crossmodal integration and recognition. (Nature Communication)](https://www.nature.com/articles/s41467-021-21404-z) |Spiking Neural Network (SNN), Multisensory, Crossmodal integration | N/A |
| 8/31 | Chen Xinyi | [Network of evolvable neural units can learn synaptic learning rules and spiking dynamics (Nature Machine Intelligence)](https://www.nature.com/articles/s42256-020-00267-x) |Biological inspired, Evolvable neural unit, Evolution strategy, Reinforcement learning|[code](https://doi.org/10.24433/CO.1361267.v1)|
| 9/7 | Yang Qu | [Short-Term Plasticity Neurons Learning to Learn and Forget (ICML 22)](https://proceedings.mlr.press/v162/rodriguez22b/rodriguez22b.pdf) |Spiking Neural Network (SNN), Short-Term Plasticity (STP)|[code](https://github.com/NeuromorphicComputing/stpn)|
| 9/14 | Chen Xinyi | [State Transition of Dendritic Spines Improves Learning of Sparse Spiking Neural Networks (ICML 22)](https://proceedings.mlr.press/v162/chen22ac.html) |Dynamic pruning algorithm, Spiking neural network, Dendritic spines |N/A|
| 9/14 | Song Zeyang | [AutoSNN: Towards Energy-Efficient Spiking Neural Networks (ICML 22)](https://arxiv.org/pdf/2201.12738.pdf) |Spiking Neural Network(SNN), Neural Architecture Search(NAS)|[code](https://github.com/nabk89/AutoSNN)|
| 9/21 | Chen Xinyi | [Designing neural networks through neuroevolution (Nature MI)](https://www.nature.com/articles/s42256-018-0006-z) |Spiking Neural Network(SNN), complex neuron model, Context-dependent segmentation|[code](https://github.com/ToshitakeAsabuki/dendritic_gating)|
| 9/28 | Yang Qu | [Multi-Level Firing with Spiking DS-ResNet: Enabling Better and Deeper Directly-Trained Spiking Neural Networks (IJCAI-22)](https://www.ijcai.org/proceedings/2022/0343.pdf) |Spiking Neural Network (SNN), Direct Training, ResNet|[code](https://github.com/langfengQ/MLF-DSResNet)|
| 9/28 | Song Zeyang| [Neural circuit mechanisms of hierarchical sequence learning tested on large-scale recording data](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010214) |Neuroevolution, Machine learning, Artificial general intelligence, Review|N/A|
| 10/5 | Zhou Xun | [Survey on Evolutionary Construction of Deep Neural Networks]| | |
| 10/12 | Chen Xinyi | [Spiking activity propagation in neuronal networks Reconciling different perspectives on neural coding](https://www.nature.com/articles/nrn2886) |Neural coding, information transmission, firing rate, synchrony|N/A |
| 10/12 | Ma Chenxiang | [LISNN: Improving Spiking Neural Networks with Lateral Interactions for Robust Object Recognition](https://www.ijcai.org/proceedings/2020/0211.pdf) |Spiking neural networks, lateral connections, neural architecture |[code](https://github.com/Delver-of-Squeakrets/LISNN)|
| 10/26 | Yang Qu | [Learning as the Unsupervised Alignment of Conceptual Systems (Nature MI)](https://www.nature.com/articles/s42256-019-0132-2) |Aligning conceptual systems, bio-inspired learning, unsupervised learning |N/A|
| 10/26 | Song Zeyang | [Spike-thrift:Towards energy-efficient deep spiking neural networks by limiting spiking activity via attention-guided compression (CVPR21)](https://openaccess.thecvf.com/content/WACV2021/papers/Kundu_Spike-Thrift_Towards_Energy-Efficient_Deep_Spiking_Neural_Networks_by_Limiting_Spiking_WACV) |Spiking Neural Network(SNN), Attention-based compression, Sparse learning| N/A |
| 11/2 | Ma Chenxiang | [Backpropagation and the brain](https://www.nature.com/articles/s41583-020-0277-3)|Backpropagation, biologically plausible learning| N/A |
| 11/9 | Yang Qu | [Knowledge Distillation: A Survey](https://arxiv.org/abs/2006.05525) |Knowledge Distillation, Knowledge transfer, Survey|[code](https://github.com/AberHu/Knowledge-Distillation-Zoo) |
| 11/9 | Chen Xinyi |  [A biological perspective on evolutionary computation (Nature MI)](https://www.nature.com/articles/s42256-020-00278-8#:~:text=Evolutionary%20computation%20is%20inspired%20by,solutions%20to%20challenging%20practical%20problems.) |Evolutionary computation, comparison|N/A |
| 11/16 | Song Zeyang| [Introducing principles of synaptic integration in the optimization of deep neural networks (Nature Communication)](https://www.nature.com/articles/s41467-022-29491-2) |Neuromorphic computing, learning algorithm |[code](https://github.com/IBM/GRAPES) |
| 11/23 | Ma Chenxiang | [Closed-form continuous-time neural networks (Nature MI)](https://www.nature.com/articles/s42256-022-00556-7) | | |
| 11/23 | Chen Xinyi | [Macroscopic Dynamics of Neural Networks with Heterogeneous Spiking Thresholds](https://arxiv.org/abs/2209.03501) | | |
| 11/30 | Song Zeyang | Survey on Neural Decoding | | |
| 12/7  | Ma Chenxiang | [Spiking Transformers for Event-Based Single Object Tracking (CVPR 22)](http://openaccess.thecvf.com//content/CVPR2022/html/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.html) | | |
| 12/7  | Chen Xinyi | [Brain-Inspired Multilayer Perceptron With Spiking Neurons (CVPR 22)](http://openaccess.thecvf.com//content/CVPR2022/html/Li_Brain-Inspired_Multilayer_Perceptron_With_Spiking_Neurons_CVPR_2022_paper.html) | | |
| 12/14  | Song Zeyang | [A convolutional neural-network model of human cochlear mechanics and filter tuning for real-time applications (Nature MI)](https://www.nature.com/articles/s42256-020-00286-8) | | |
| 12/21  | Ma Chenxiang | [Exploring Lottery Ticket Hypothesis in Spiking Neural Networks (ECCV 22)](http://www.ecva.net/papers/eccv_2022/papers_ECCV/html/7345_ECCV_2022_paper.php) | | |
| 12/21  | Chen Xinyi | [Neural Architecture Search for Spiking Neural Networks (ECCV 22)](http://www.ecva.net/papers/eccv_2022/papers_ECCV/html/599_ECCV_2022_paper.php) | | |
| 12/28  | Yang Qu | [Embodied Intelligence via Learning and Evolution (Nature Communications)](https://www.nature.com/articles/s41467-021-25874-z) | | |
| 12/28  | Song Zeyang | [A convolutional neural-network framework for modelling auditory sensory cells and synapses (Nature Communications Biology)](https://www.nature.com/articles/s42003-021-02341-5) | | |
| 1/4  | Yang Qu | [RecDis-SNN: Rectifying Membrane Potential Distribution for Directly Training Spiking Neural Networks (CVPR 22)](http://openaccess.thecvf.com//content/CVPR2022/html/Guo_RecDis-SNN_Rectifying_Membrane_Potential_Distribution_for_Directly_Training_Spiking_Neural_CVPR_2022_paper.html) | | |
| 1/4 | Yang Qu | [Network Binarization via Contrastive Learning](https://arxiv.org/pdf/2207.02970.pdf) | | |

# Presentation Slides 
[Google Drive](https://drive.google.com/drive/folders/1NeEbtNGvgO8z0j7RLd0dtGQz6jp1WklV?usp=sharing) 

# Continue Updating
- Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs 
- Backpropagation through the Void: Optimizing control variates for black-box gradient estimation
- Convolutional Neural Networks as a Model of the Visual System: Past, Present, and Future
- Replay in Deep Learning: Current Approaches and Missing Biological Elements 
- Perception in real-time: predicting the present, reconstructing the past
- Evolutionary training and abstraction yields algorithmic generalization of neural computers
- Compartmentalized dendritic plasticity during associative learning (Science)
- Current State and Future Directions for Learning in Biological Recurrent Neural Networks: A Perspective Piece
- Hypothesis-driven Online Video Stream Learning with Augmented Memory（https://arxiv.org/abs/2104.02206）
- GAN Memory with No Forgetting (NIPS 2020)](https://papers.nips.cc/paper/2020/file/bf201d5407a6509fa536afc4b380577e-Paper.pdf)
- Transfer without Forgetting https://arxiv.org/pdf/2206.00388.pdf
- Towards mental time travel: a hierarchical memory for reinforcement learning agents
- Memory-inspired spiking hyperdimensional network for robust online learning
- Dendritic predictive coding: A theory of cortical computation with spiking neurons https://arxiv.org/pdf/2205.05303.pdf
- Beyond accuracy: generalization properties of bio-plausible temporal credit assignment rules https://arxiv.org/pdf/2206.00823.pdf
- Biologically-plausible backpropagation through arbitrary timespans via local neuromodulators https://arxiv.org/pdf/2206.01338.pdf
- Neuromorphic computing chip with spatiotemporal elasticity for multi-intelligent-tasking robots
- Spike Calibration: Fast and Accurate Conversion of Spiking Neural Network for Object Detection and Segmentation
- Learning in deep neural networks and brains with similarity-weighted interleaved learning (PNAS)
- Gradient-based Neuromorphic Learning on Dynamical RRAM Arrays (https://arxiv.org/pdf/2206.12992.pdf)
- Modeling Associative Plasticity between Synapses to Enhance Learning of Spiking Neural Networks https://arxiv.org/pdf/2207.11670.pdf
- Single-phase deep learning in cortico-cortical networks (https://arxiv.org/pdf/2206.11769.pdf)
- Online Normalization for Training Neural Networks (https://papers.nips.cc/paper/2019/hash/cb3ce9b06932da6faaa7fc70d5b5d2f4-Abstract.html)
- Neuro-symbolic computing with spiking neural networks (https://arxiv.org/pdf/2208.02576.pdf)
- Cell-type-specific integration of feedforward and feedback synaptic inputs in the posterior parietal cortex (NEURON)
- Optimizing Recurrent Spiking Neural Networks with Small Time Constants for Temporal Tasks
- Multimodal Speech Enhancement Using Burst Propagation
- Benchmarking Neuromorphic Computing for Inference (https://www.researchgate.net/profile/Simon-Narduzzi/publication/362412429_Benchmarking_Neuromorphic_Computing_for_Inference/links/630735aa61e4553b95389cf0/Benchmarking-Neuromorphic-Computing-for-Inference.pdf)
- Cognitive Neuroscience of Time: Nows, Timelines, and Chronologies
- Interactive continual learning for robots: a neuromorphic approach http://sandamirskaya.eu/resources/Interactive_Continual_Learning_for_Robots__Neuromorphic_Approach__ICONS_.pdf
- The neural coding framework for learning generative models
- Continual Learning of Recurrent Neural Networks by Locally Aligning Distributed Representations
- The cortical column: a structure without a function
- Learning on Arbitrary Graph Topologies via Predictive Coding https://arxiv.org/pdf/2201.13180.pdf
- Online Training Through Time for Spiking Neural Networks https://arxiv.org/pdf/2210.04195.pdf
- STSC-SNN: Spatio-Temporal Synaptic Connection with Temporal Convolution and Attention for Spiking Neural Networks https://arxiv.org/pdf/2210.05241.pdf
- Understanding the role of individual units in a deep neural network. PNAS
- Exploring the Brain-like Properties of Deep Neural Networks A Neural Encoding Perspective
- Denoised Internal Models: A Brain-inspired Autoencoder Against Adversarial Attacks
- Towards a New Paradigm for Brain-inspired Computer Vision
- A Computational Model for Storing Memories in the Synaptic Structures of the Brain
- Towards Accurate, Energy-Efficient, & Low-Latency Spiking LSTMs
- An Analytical Estimation of Spiking Neural Networks Energy Efficiency
- Sparse bursts optimize information transmission in a multiplexed neural code (PNAS)
- Current State and Future Directions for Learning in Biological Recurrent Neural Networks: A Perspective Piece
- [Spike Transformer: Monocular Depth Estimation for Spiking Camera (ECCV 22)](http://www.ecva.net/papers/eccv_2022/papers_ECCV/html/3125_ECCV_2022_paper.php)
- [Towards Ultra Low Latency Spiking Neural Networks for Vision and Sequential Tasks Using Temporal Pruning (ECCV 22)](http://www.ecva.net/papers/eccv_2022/papers_ECCV/html/6421_ECCV_2022_paper.php)
- [Real Spike: Learning Real-Valued Spikes for Spiking Neural Networks (ECCV 22)](http://www.ecva.net/papers/eccv_2022/papers_ECCV/html/6623_ECCV_2022_paper.php)
- Recent Advances at the Interface of Neuroscience and Artificial Neural Networks
- DDDM: A Brain-Inspired Framework for Robust Classification (IJCAI-22)
- SimAM: A Simple, Parameter-Free Attention Module for Convolutional Neural Networks (ICML-21)
- Neuromorphic Data Augmentation for Training Spiking Neural Networks (ECCV 22)
- Event-Based Video Reconstruction Via Potential-Assisted Spiking Neural Network (CVPR 22)
